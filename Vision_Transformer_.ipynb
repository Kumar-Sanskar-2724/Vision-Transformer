{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpeFPN/VnCxoS0tFpT5gf3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kumar-Sanskar-2724/Vision-Transformer/blob/main/Vision_Transformer_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets,transforms\n",
        "import timm\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "# Get going_modular directory\n",
        "try:\n",
        "  from going_modular.going_modular import data_setup,engine\n",
        "  from helper_functions import plot_loss_curves,set_seeds,download_data\n",
        "except:\n",
        "  print(f\"[INFO] Couldn't find going_modular and helper_functions directory, downloading them from GitHub...\")\n",
        "  !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "  !mv pytorch-deep-learning/helper_functions.py .\n",
        "  !rm -rf pytorch-deep-learning\n",
        "  from going_modular.going_modular import data_setup,engine\n",
        "  from helper_functions import download_data,set_seeds,plot_loss_curves"
      ],
      "metadata": {
        "id": "_0oSapi3rz52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Devic Agnostic Code"
      ],
      "metadata": {
        "id": "_rgTAiwZss9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "AgX9z9f5tgFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "X7uRjLPY0F0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Data"
      ],
      "metadata": {
        "id": "Yt2W7jy4uRwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data',train=True,transform=transform,download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data',train=False,transform=transform,download=True)"
      ],
      "metadata": {
        "id": "DvF2Ftv-uU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=train_dataset.classes\n",
        "class_names\n",
        "class_idx = train_dataset.class_to_idx\n",
        "class_idx"
      ],
      "metadata": {
        "id": "S1y6vJoxXriz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = download_data(source='https://github.com/Kumar-Sanskar-2724/Vision-Transformer/raw/refs/heads/main/examples/examples.zip',destination='examples')"
      ],
      "metadata": {
        "id": "AUtba69UMSZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    0: 'airplane',\n",
        "    1: 'automobile',\n",
        "    2: 'bird',\n",
        "    3: 'cat',\n",
        "    4: 'deer',\n",
        "    5: 'dog',\n",
        "    6: 'frog',\n",
        "    7: 'horse',\n",
        "    8: 'ship',\n",
        "    9: 'truck'\n",
        "}"
      ],
      "metadata": {
        "id": "6uXwKuAgkzVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=64,shuffle=False)"
      ],
      "metadata": {
        "id": "FoMDpdoN0djn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Model"
      ],
      "metadata": {
        "id": "T9mKkYA30uvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('vit_tiny_patch16_224',pretrained=True)\n",
        "model.head = nn.Linear(in_features=model.head.in_features,out_features=10)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "F3VV7oFH0yvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a function to time our experiments"
      ],
      "metadata": {
        "id": "rPKoPGnW4lPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start:float,\n",
        "                     end:float,\n",
        "                     device:torch.device=None):\n",
        "  \"\"\" Prints difference between start time and end time\"\"\"\n",
        "  train_time = end - start\n",
        "  print(f\"Total train time on:{device} {train_time:.3f} seconds\")\n",
        "  return train_time"
      ],
      "metadata": {
        "id": "feUTQMcx4qwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "TdTx6KIa1PiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),lr=3e-5)"
      ],
      "metadata": {
        "id": "PiRBwnLR2HUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine\n",
        "set_seeds()\n",
        "model_results = engine.train(model=model,\n",
        "                             train_dataloader=train_dataloader,\n",
        "                             test_dataloader=test_dataloader,\n",
        "                             optimizer=optimizer,\n",
        "                             loss_fn=loss_fn,\n",
        "                             epochs=3,\n",
        "                             device=device)"
      ],
      "metadata": {
        "id": "Cj0okHtKUYnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving our model"
      ],
      "metadata": {
        "id": "Y4nFvc1PJQ1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import utils\n",
        "utils.save_model(model=model,\n",
        "                 target_dir='models',\n",
        "                 model_name='ViT_feature_extractor.pth')"
      ],
      "metadata": {
        "id": "9xvsR_OsJS1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deplyoment"
      ],
      "metadata": {
        "id": "n9LPUwnKJdai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import/install gradio\n",
        "try:\n",
        "  import gradio as gr\n",
        "except:\n",
        "  !pip -q install gradio\n",
        "  import gradio as gr"
      ],
      "metadata": {
        "id": "b4yV2Jw0f3gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-collect example images\n",
        "import glob\n",
        "example_list = [[path] for path in glob.glob(\"data/examples/*.jpg\")]\n",
        "example_list"
      ],
      "metadata": {
        "id": "lC60QcGKLeYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image):\n",
        "    image = image.convert(\"RGB\")\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        predicted_class = output.argmax(1).item()\n",
        "\n",
        "    return f\"Predicted Class: {label_map[predicted_class]}\""
      ],
      "metadata": {
        "id": "J9r0kUtIlbSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs='text',\n",
        "    examples= example_list,\n",
        "    title=\"Vision Transformer CIFAR-10 Classifier\",\n",
        "    description=\"Upload a CIFAR-10 image, and the ViT Tiny model will predict the class.\"\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "ftdzk0JujBgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning our CIFAR Model into a deployable app"
      ],
      "metadata": {
        "id": "lGpAK7WPjL_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a `demos` folder to store our CIFAR app files"
      ],
      "metadata": {
        "id": "66WxjxRpGR1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Create CIFAR with demo path\n",
        "cifar = Path('demo/cifar')\n",
        "\n",
        "# Remove files that might exist and create a new directory\n",
        "if cifar.exists():\n",
        "  shutil.rmtree(cifar)\n",
        "  cifar.mkdir(parents=True,exist_ok=True)\n",
        "else:\n",
        "  cifar.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "!ls demo/cifar"
      ],
      "metadata": {
        "id": "6BmT0EzAGhn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a folder of example images to use with our CIFAR demo"
      ],
      "metadata": {
        "id": "LwmgQCmJHYc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create an example directory\n",
        "cifar_example_path = cifar/'examples'\n",
        "cifar_example_path.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "# Collect 3 random test dataset image path\n",
        "cifar_examples = [Path('data/examples/Airplane.jpg'),\n",
        "                            Path('data/examples/automobile.jpg'),\n",
        "                            Path('data/examples/bird.jpg')]\n",
        "\n",
        "# Copy the three images to the examples directory\n",
        "for example in cifar_examples:\n",
        "  destination = cifar_example_path/example.name\n",
        "  print(f'[INFO] Copying {example} to {destination}')\n",
        "  shutil.copy2(src=example,\n",
        "              dst=destination)"
      ],
      "metadata": {
        "id": "n0ZrMiAgHnZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "example_list = [['examples/'+example] for example in os.listdir(cifar_example_path)]\n",
        "example_list"
      ],
      "metadata": {
        "id": "GDttr0UQI0yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving our trained Tiny ViT model to our CIFAR demo directory"
      ],
      "metadata": {
        "id": "DkmCESGgJDST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create a source path for our target model\n",
        "tiny_vit_model_path = 'models/ViT_feature_extractor.pth'\n",
        "\n",
        "# Create a destination path for our target model\n",
        "tiny_vit_destination = cifar/tiny_vit_model_path.split('/')[1]\n",
        "\n",
        "# Try to move the model file\n",
        "try:\n",
        "  print(f'[INFO] Attmepting to move :{tiny_vit_model_path} to {tiny_vit_destination}')\n",
        "\n",
        "  # Move the model\n",
        "  shutil.move(src=tiny_vit_model_path,\n",
        "              dst=tiny_vit_destination)\n",
        "  print(f'[INFO] Model move complete')\n",
        "\n",
        "except:\n",
        "  print(f\"[INFO] No model found at {tiny_vit_model_path}, perhaps its already been moved?\")\n",
        "  print(f\"[INFO] Model exists at {tiny_vit_destination}: {tiny_vit_destination.exists()}\")"
      ],
      "metadata": {
        "id": "PXGZh7AaJnO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning off Tiny_ViT model into a Python script (model.py)"
      ],
      "metadata": {
        "id": "YuqCTJTON1uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/cifar/model.py\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "def create_model(num_classes:int=10,\n",
        "                 seeds:int=42):\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "  model = timm.create_model('vit_tiny_patch16_224',pretrained=True)\n",
        "  model.head = nn.Linear(in_features=model.head.in_features,out_features=10)\n",
        "\n",
        "  return model,transform"
      ],
      "metadata": {
        "id": "3SRO9V-rQ25X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "id": "6OqZlhisS4iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning our Tiny_ViT Gradio app into a Python script(app.py)"
      ],
      "metadata": {
        "id": "OhGm2mFuT4f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/cifar/app.py\n",
        "### 1. Imports and class names setup ###\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from model import create_model\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple,Dict\n",
        "\n",
        "# Setup class names\n",
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "### 2. Model and transforms perparation ###\n",
        "tiny_vit,tiny_vit_transforms = create_model(num_classes=10)\n",
        "\n",
        "# Load save weights\n",
        "tiny_vit.load_state_dict(torch.load(f='ViT_feature_extractor.pth',\n",
        "                                    map_location=torch.device('cpu')))\n",
        "\n",
        "# Predict function\n",
        "def predict(image):\n",
        "    # Make sure the image is in RGB\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    # Apply the necessary transformation for your model\n",
        "    input_tensor = tiny_vit_transforms(image).unsqueeze(0)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    tiny_vit.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get the model's raw output (logits)\n",
        "        output = tiny_vit(input_tensor)\n",
        "\n",
        "        # Apply softmax to convert logits to probabilities\n",
        "        pred_probs = torch.softmax(output, dim=1)\n",
        "\n",
        "    # Create a dictionary mapping class names to their probabilities\n",
        "    pred_label_and_probs = {\n",
        "        class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))\n",
        "    }\n",
        "\n",
        "    return pred_label_and_probs\n",
        "\n",
        "# Gradio app\n",
        "title=\"Vision Transformer CIFAR-10 Classifier\",\n",
        "description=\"Upload a CIFAR-10 image, and the ViT Tiny model will predict the class.\"\n",
        "\n",
        "# Creating example list\n",
        "example_list =[['examples/'+example] for example in os.listdir('examples')]\n",
        "\n",
        "# Create the gradio demo\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs='text',\n",
        "    examples= example_list,\n",
        "    title=\"Vision Transformer CIFAR-10 Classifier\",\n",
        "    description=\"Upload a CIFAR-10 image, and the ViT Tiny model will predict the class.\"\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "mKFrHS2JT_A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a requirement file `requirements.txt`"
      ],
      "metadata": {
        "id": "RbL4vw4-W0ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo/cifar/requirements.txt\n",
        "torch >= 1.12.0\n",
        "torchvision >= 0.13.0\n",
        "gradio >= 3.1.4\n",
        "timm"
      ],
      "metadata": {
        "id": "0d3LR7LaXmlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Deploying our FoodVision Mini app HuggingFace Spaces"
      ],
      "metadata": {
        "id": "JpHF5BnUXnkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls demo/cifar/examples/"
      ],
      "metadata": {
        "id": "JZsQc2vqXw6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change into the foodvision_mini directory and then zip it from the inside\n",
        "!cd demo/cifar && zip -r ../cifar.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\""
      ],
      "metadata": {
        "id": "I0gQXLtvX0mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('demo/cifar.zip')\n",
        "except:\n",
        "  print(f\"Not running in Google Colab, can't use google.colab.files.download(), please download foodvision_mini.zip manually.\")"
      ],
      "metadata": {
        "id": "BeOKX0vZX-IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OPGFLalmYDHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}